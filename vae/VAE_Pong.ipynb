{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(I):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I = I[::2,::2,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    #I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    #I = I[:-1,:,0]\n",
    "    return I.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data to use for training\n",
    "env = gym.make(\"Pong-v0\")\n",
    "observation = env.reset()\n",
    "t = 300\n",
    "obs = []\n",
    "for i in range(t):\n",
    "    observation,_,_,_ = env.step(env.action_space.sample())\n",
    "    obs.append(prepro(observation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dim = prepro(observation).size\n",
    "Z_dim = 100\n",
    "h_dim = 128\n",
    "c = 0\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / np.sqrt(in_dim / 2.)\n",
    "    return Variable(torch.randn(*size) * xavier_stddev, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxh = xavier_init(size=[X_dim, h_dim])\n",
    "#bxh = Variable(torch.zeros(h_dim), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Whz_mu = xavier_init(size=[h_dim, Z_dim])\n",
    "#bhz_mu = Variable(torch.zeros(Z_dim), requires_grad=True)\n",
    "\n",
    "Whz_var = xavier_init(size=[h_dim, Z_dim])\n",
    "#bhz_var = Variable(torch.zeros(Z_dim), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(X):\n",
    "    #h = nn.relu(X.matmul(Wxh) + bxh.repeat(X.size(0), 1))\n",
    "    h = nn.relu(X.matmul(Wxh))\n",
    "    #print(h.shape)\n",
    "    #z_mu = h.matmul(Whz_mu) + bhz_mu.repeat(h.size(0), 1)\n",
    "    #z_var = h.matmul(Whz_var) + bhz_var.repeat(h.size(0), 1)\n",
    "    z_mu = h.matmul(Whz_mu)\n",
    "    z_var = h.matmul(Whz_var)\n",
    "    return z_mu, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_z(mu, log_var):\n",
    "    # Using reparameterization trick to sample from a gaussian\n",
    "    eps = Variable(torch.randn(mb_size, Z_dim))\n",
    "    #print(eps.shape)\n",
    "    return mu + torch.exp(log_var / 2) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wzh = xavier_init(size=[Z_dim, h_dim])\n",
    "#bzh = Variable(torch.zeros(h_dim), requires_grad=True)\n",
    "\n",
    "Whx = xavier_init(size=[h_dim, X_dim])\n",
    "#bhx = Variable(torch.zeros(X_dim), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(z):\n",
    "    #print(z.shape)\n",
    "    #h = nn.relu(z.matmul(Wzh) + bzh.repeat(z.size(0), 1))\n",
    "    h = nn.relu(z.matmul(Wzh))\n",
    "    #print(h.shape)\n",
    "    #X = torch.sigmoid(h.matmul(Whx) + bhx.repeat(h.size(0), 1))\n",
    "    X = torch.sigmoid(h.matmul(Whx))\n",
    "    #print(X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = [Wxh, bxh, Whz_mu, bhz_mu, Whz_var, bhz_var, Wzh, bzh, Whx, bhx]\n",
    "params = [Wxh, Whz_mu, Whz_var, Wzh, Whx]\n",
    "\n",
    "solver = optim.Adam(params, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, tensor(32682552., grad_fn=<ThAddBackward>))\n",
      "(2, tensor(1045214.8750, grad_fn=<ThAddBackward>))\n",
      "(4, tensor(16366830., grad_fn=<ThAddBackward>))\n",
      "(6, tensor(8841957., grad_fn=<ThAddBackward>))\n",
      "(8, tensor(112620.6172, grad_fn=<ThAddBackward>))\n",
      "(10, tensor(27842.1699, grad_fn=<ThAddBackward>))\n",
      "(12, tensor(18083.3105, grad_fn=<ThAddBackward>))\n",
      "(14, tensor(1017455.1250, grad_fn=<ThAddBackward>))\n",
      "(16, tensor(1181759.3750, grad_fn=<ThAddBackward>))\n",
      "(18, tensor(897115.5000, grad_fn=<ThAddBackward>))\n",
      "(20, tensor(98178377337113435038547968., grad_fn=<ThAddBackward>))\n",
      "(22, tensor(31062418628800771323968094208., grad_fn=<ThAddBackward>))\n",
      "(24, tensor(580841382550343516160., grad_fn=<ThAddBackward>))\n",
      "(26, tensor(5492958165419672720293448646656., grad_fn=<ThAddBackward>))\n",
      "(28, tensor(128818253222848336886759424., grad_fn=<ThAddBackward>))\n",
      "(30, tensor(102731679410547532211683328., grad_fn=<ThAddBackward>))\n",
      "(32, tensor(99284510205475291136., grad_fn=<ThAddBackward>))\n",
      "(34, tensor(147426635623740473344., grad_fn=<ThAddBackward>))\n",
      "(36, tensor(24278802237061332992., grad_fn=<ThAddBackward>))\n",
      "(38, tensor(2238240086535700480., grad_fn=<ThAddBackward>))\n",
      "(40, tensor(20489501924787009156546560., grad_fn=<ThAddBackward>))\n",
      "(42, tensor(512456931405373374464., grad_fn=<ThAddBackward>))\n",
      "(44, tensor(1765379332374528., grad_fn=<ThAddBackward>))\n",
      "(46, tensor(137528919911431143424., grad_fn=<ThAddBackward>))\n",
      "(48, tensor(50921858713106518114304., grad_fn=<ThAddBackward>))\n",
      "(50, tensor(98051122660376576., grad_fn=<ThAddBackward>))\n",
      "(52, tensor(19002695433309929865216., grad_fn=<ThAddBackward>))\n",
      "(54, tensor(60340199775788859392., grad_fn=<ThAddBackward>))\n",
      "(56, tensor(50397159136165888., grad_fn=<ThAddBackward>))\n",
      "(58, tensor(168609558363635712., grad_fn=<ThAddBackward>))\n",
      "(60, tensor(190805159075381248., grad_fn=<ThAddBackward>))\n",
      "(62, tensor(988873240465061212848128., grad_fn=<ThAddBackward>))\n",
      "(64, tensor(1246570754328634910232805376., grad_fn=<ThAddBackward>))\n",
      "(66, tensor(13917101714571264., grad_fn=<ThAddBackward>))\n",
      "(68, tensor(43564106686398464., grad_fn=<ThAddBackward>))\n",
      "(70, tensor(735065167171158016., grad_fn=<ThAddBackward>))\n",
      "(72, tensor(1438412395148424775729152., grad_fn=<ThAddBackward>))\n",
      "(74, tensor(135764738310144., grad_fn=<ThAddBackward>))\n",
      "(76, tensor(73517181698048., grad_fn=<ThAddBackward>))\n",
      "(78, tensor(15710481415143424., grad_fn=<ThAddBackward>))\n",
      "(80, tensor(1533390700412928., grad_fn=<ThAddBackward>))\n",
      "(82, tensor(64492132131897060884480., grad_fn=<ThAddBackward>))\n",
      "(84, tensor(90649260982272., grad_fn=<ThAddBackward>))\n",
      "(86, tensor(1176914361252919115776., grad_fn=<ThAddBackward>))\n",
      "(88, tensor(13233265311679518582243328., grad_fn=<ThAddBackward>))\n",
      "(90, tensor(1165370458112., grad_fn=<ThAddBackward>))\n",
      "(92, tensor(9357470066437855090049024., grad_fn=<ThAddBackward>))\n",
      "(94, tensor(2172449558785117529309184., grad_fn=<ThAddBackward>))\n",
      "(96, tensor(4054271918080., grad_fn=<ThAddBackward>))\n",
      "(98, tensor(2221558433558036480., grad_fn=<ThAddBackward>))\n",
      "(100, tensor(1060060069888., grad_fn=<ThAddBackward>))\n",
      "(102, tensor(229143497448357888., grad_fn=<ThAddBackward>))\n",
      "(104, tensor(469234874318848., grad_fn=<ThAddBackward>))\n",
      "(106, tensor(175670319644672., grad_fn=<ThAddBackward>))\n",
      "(108, tensor(306272993280., grad_fn=<ThAddBackward>))\n",
      "(110, tensor(1759836355636439036953886720., grad_fn=<ThAddBackward>))\n",
      "(112, tensor(43923426845837492224., grad_fn=<ThAddBackward>))\n",
      "(114, tensor(53148659256366465024., grad_fn=<ThAddBackward>))\n",
      "(116, tensor(2317468786029012519547918352384., grad_fn=<ThAddBackward>))\n",
      "(118, tensor(13769811317077766885448317099048960., grad_fn=<ThAddBackward>))\n",
      "(120, tensor(6984941158663377125376., grad_fn=<ThAddBackward>))\n",
      "(122, tensor(5160001472083001344., grad_fn=<ThAddBackward>))\n",
      "(124, tensor(145124143136768., grad_fn=<ThAddBackward>))\n",
      "(126, tensor(729095662993408., grad_fn=<ThAddBackward>))\n",
      "(128, tensor(19389088792576., grad_fn=<ThAddBackward>))\n",
      "(130, tensor(385690664960., grad_fn=<ThAddBackward>))\n",
      "(132, tensor(1401854642618368., grad_fn=<ThAddBackward>))\n",
      "(134, tensor(377913467731968., grad_fn=<ThAddBackward>))\n",
      "(136, tensor(360086110208., grad_fn=<ThAddBackward>))\n",
      "(138, tensor(849787420672., grad_fn=<ThAddBackward>))\n",
      "(140, tensor(582441202205327360., grad_fn=<ThAddBackward>))\n",
      "(142, tensor(111352144199680., grad_fn=<ThAddBackward>))\n",
      "(144, tensor(24485239187308544., grad_fn=<ThAddBackward>))\n",
      "(146, tensor(50888829313439382896640., grad_fn=<ThAddBackward>))\n",
      "(148, tensor(86407854883382029713408., grad_fn=<ThAddBackward>))\n",
      "(150, tensor(1846860764252555182080., grad_fn=<ThAddBackward>))\n",
      "(152, tensor(1393435082752., grad_fn=<ThAddBackward>))\n",
      "(154, tensor(17658521814302720., grad_fn=<ThAddBackward>))\n",
      "(156, tensor(1526192367359777308672., grad_fn=<ThAddBackward>))\n",
      "(158, tensor(44313875418509507465052160., grad_fn=<ThAddBackward>))\n",
      "(160, tensor(32007946767861547008., grad_fn=<ThAddBackward>))\n",
      "(162, tensor(5426906820213997568., grad_fn=<ThAddBackward>))\n",
      "(164, tensor(5490205564109938764273418240., grad_fn=<ThAddBackward>))\n",
      "(166, tensor(37724977442384570484785152., grad_fn=<ThAddBackward>))\n",
      "(168, tensor(678233266557288448., grad_fn=<ThAddBackward>))\n",
      "(170, tensor(1746337192214528., grad_fn=<ThAddBackward>))\n",
      "(172, tensor(178143750105595904., grad_fn=<ThAddBackward>))\n",
      "(174, tensor(851235780143435743232., grad_fn=<ThAddBackward>))\n",
      "(176, tensor(189938838536192., grad_fn=<ThAddBackward>))\n",
      "(178, tensor(297083760279552., grad_fn=<ThAddBackward>))\n",
      "(180, tensor(5134757888., grad_fn=<ThAddBackward>))\n",
      "(182, tensor(180631343623831552., grad_fn=<ThAddBackward>))\n",
      "(184, tensor(184834001469440., grad_fn=<ThAddBackward>))\n",
      "(186, tensor(91747364800299008., grad_fn=<ThAddBackward>))\n",
      "(188, tensor(1855299304554496., grad_fn=<ThAddBackward>))\n",
      "(190, tensor(15515863117517329285513216., grad_fn=<ThAddBackward>))\n",
      "(192, tensor(2107621953446608896., grad_fn=<ThAddBackward>))\n",
      "(194, tensor(5583431096520933376., grad_fn=<ThAddBackward>))\n",
      "(196, tensor(171795859498046849024., grad_fn=<ThAddBackward>))\n",
      "(198, tensor(38758825066496., grad_fn=<ThAddBackward>))\n",
      "(200, tensor(106200186880., grad_fn=<ThAddBackward>))\n",
      "(202, tensor(699651044933632., grad_fn=<ThAddBackward>))\n",
      "(204, tensor(7515425042595840., grad_fn=<ThAddBackward>))\n",
      "(206, tensor(2571373554393598132224., grad_fn=<ThAddBackward>))\n",
      "(208, tensor(23999931219968., grad_fn=<ThAddBackward>))\n",
      "(210, tensor(11815748691060569669632., grad_fn=<ThAddBackward>))\n",
      "(212, tensor(29222889708087263887360., grad_fn=<ThAddBackward>))\n",
      "(214, tensor(424284189493403952267395072., grad_fn=<ThAddBackward>))\n",
      "(216, tensor(8800347235006004854784., grad_fn=<ThAddBackward>))\n",
      "(218, tensor(1055585519771058176., grad_fn=<ThAddBackward>))\n",
      "(220, tensor(12592436089978880., grad_fn=<ThAddBackward>))\n",
      "(222, tensor(39569030381568., grad_fn=<ThAddBackward>))\n",
      "(224, tensor(10030089764864., grad_fn=<ThAddBackward>))\n",
      "(226, tensor(1207600128., grad_fn=<ThAddBackward>))\n",
      "(228, tensor(16640582656., grad_fn=<ThAddBackward>))\n",
      "(230, tensor(406738599936., grad_fn=<ThAddBackward>))\n",
      "(232, tensor(492359909376., grad_fn=<ThAddBackward>))\n",
      "(234, tensor(1706738639569944576., grad_fn=<ThAddBackward>))\n",
      "(236, tensor(7660260660574390994337792., grad_fn=<ThAddBackward>))\n",
      "(238, tensor(8700407855675026178048., grad_fn=<ThAddBackward>))\n",
      "(240, tensor(2582340765220864., grad_fn=<ThAddBackward>))\n",
      "(242, tensor(14867448597161787260928., grad_fn=<ThAddBackward>))\n",
      "(244, tensor(9628179585040384., grad_fn=<ThAddBackward>))\n",
      "(246, tensor(21499729920., grad_fn=<ThAddBackward>))\n",
      "(248, tensor(1517222430244864., grad_fn=<ThAddBackward>))\n",
      "(250, tensor(127148398897294303297536., grad_fn=<ThAddBackward>))\n",
      "(252, tensor(18566049881416269824., grad_fn=<ThAddBackward>))\n",
      "(254, tensor(23972330602496., grad_fn=<ThAddBackward>))\n",
      "(256, tensor(357963445305344., grad_fn=<ThAddBackward>))\n",
      "(258, tensor(24273295763343303170326528., grad_fn=<ThAddBackward>))\n",
      "(260, tensor(2439981598215017332736., grad_fn=<ThAddBackward>))\n",
      "(262, tensor(1486774330146240331776., grad_fn=<ThAddBackward>))\n",
      "(264, tensor(47663764471808., grad_fn=<ThAddBackward>))\n",
      "(266, tensor(59442867067682816., grad_fn=<ThAddBackward>))\n",
      "(268, tensor(956688128368269328384., grad_fn=<ThAddBackward>))\n",
      "(270, tensor(78758232981504., grad_fn=<ThAddBackward>))\n",
      "(272, tensor(447855001600., grad_fn=<ThAddBackward>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(274, tensor(1185553580032., grad_fn=<ThAddBackward>))\n",
      "(276, tensor(66931040256., grad_fn=<ThAddBackward>))\n",
      "(278, tensor(3411168512., grad_fn=<ThAddBackward>))\n",
      "(280, tensor(212433159323648., grad_fn=<ThAddBackward>))\n",
      "(282, tensor(105286266257408., grad_fn=<ThAddBackward>))\n",
      "(284, tensor(21807048640676705075200., grad_fn=<ThAddBackward>))\n",
      "(286, tensor(6283699734434352726016., grad_fn=<ThAddBackward>))\n",
      "(288, tensor(1299314193580687360., grad_fn=<ThAddBackward>))\n",
      "(290, tensor(3728774406743822214103040., grad_fn=<ThAddBackward>))\n",
      "(292, tensor(8824555770478592., grad_fn=<ThAddBackward>))\n",
      "(294, tensor(1418393984., grad_fn=<ThAddBackward>))\n",
      "(296, tensor(44894433280., grad_fn=<ThAddBackward>))\n",
      "(298, tensor(11573479161394840435949568., grad_fn=<ThAddBackward>))\n",
      "(300, tensor(1090992.6250, grad_fn=<ThAddBackward>))\n",
      "(302, tensor(434258.6250, grad_fn=<ThAddBackward>))\n",
      "(304, tensor(177655.6562, grad_fn=<ThAddBackward>))\n",
      "(306, tensor(94244.7188, grad_fn=<ThAddBackward>))\n",
      "(308, tensor(12089.5918, grad_fn=<ThAddBackward>))\n",
      "(310, tensor(18611.9941, grad_fn=<ThAddBackward>))\n",
      "(312, tensor(123930.6719, grad_fn=<ThAddBackward>))\n",
      "(314, tensor(157675.8750, grad_fn=<ThAddBackward>))\n",
      "(316, tensor(72830.2031, grad_fn=<ThAddBackward>))\n",
      "(318, tensor(55906510334674593644544., grad_fn=<ThAddBackward>))\n",
      "(320, tensor(3441049323211302371328., grad_fn=<ThAddBackward>))\n",
      "(322, tensor(148495888691520077824., grad_fn=<ThAddBackward>))\n",
      "(324, tensor(266130708377046454632448., grad_fn=<ThAddBackward>))\n",
      "(326, tensor(336212903138112459671339008., grad_fn=<ThAddBackward>))\n",
      "(328, tensor(13609595879253413684890597542854656., grad_fn=<ThAddBackward>))\n",
      "(330, tensor(47880779357776152212013056., grad_fn=<ThAddBackward>))\n",
      "(332, tensor(130035151408201728., grad_fn=<ThAddBackward>))\n",
      "(334, tensor(2255567036874752., grad_fn=<ThAddBackward>))\n",
      "(336, tensor(400760714035200., grad_fn=<ThAddBackward>))\n",
      "(338, tensor(76153098929533091840., grad_fn=<ThAddBackward>))\n",
      "(340, tensor(258232532992., grad_fn=<ThAddBackward>))\n",
      "(342, tensor(60407943266304., grad_fn=<ThAddBackward>))\n",
      "(344, tensor(889581813628928., grad_fn=<ThAddBackward>))\n",
      "(346, tensor(2844366282681078513664., grad_fn=<ThAddBackward>))\n",
      "(348, tensor(420709159403520., grad_fn=<ThAddBackward>))\n",
      "(350, tensor(3264549594639955394560., grad_fn=<ThAddBackward>))\n",
      "(352, tensor(1404068239771697152., grad_fn=<ThAddBackward>))\n",
      "(354, tensor(264421310464., grad_fn=<ThAddBackward>))\n",
      "(356, tensor(734244962304., grad_fn=<ThAddBackward>))\n",
      "(358, tensor(8931909828608., grad_fn=<ThAddBackward>))\n",
      "(360, tensor(17819432052113581015040., grad_fn=<ThAddBackward>))\n",
      "(362, tensor(450526936301568., grad_fn=<ThAddBackward>))\n",
      "(364, tensor(23007904923648., grad_fn=<ThAddBackward>))\n",
      "(366, tensor(2804873936073689923584., grad_fn=<ThAddBackward>))\n",
      "(368, tensor(669310389321728., grad_fn=<ThAddBackward>))\n",
      "(370, tensor(69718061992439185408., grad_fn=<ThAddBackward>))\n",
      "(372, tensor(203801764472815616., grad_fn=<ThAddBackward>))\n",
      "(374, tensor(182617194496., grad_fn=<ThAddBackward>))\n",
      "(376, tensor(3248192487424., grad_fn=<ThAddBackward>))\n",
      "(378, tensor(20635264745472., grad_fn=<ThAddBackward>))\n",
      "(380, tensor(303770426822098944., grad_fn=<ThAddBackward>))\n",
      "(382, tensor(19336317150301257728., grad_fn=<ThAddBackward>))\n",
      "(384, tensor(4536204562772751548416., grad_fn=<ThAddBackward>))\n",
      "(386, tensor(1006887600021045248., grad_fn=<ThAddBackward>))\n",
      "(388, tensor(14661464083305022357504., grad_fn=<ThAddBackward>))\n",
      "(390, tensor(16252172354191360., grad_fn=<ThAddBackward>))\n",
      "(392, tensor(174635055929830682918912., grad_fn=<ThAddBackward>))\n",
      "(394, tensor(139321063505920., grad_fn=<ThAddBackward>))\n",
      "(396, tensor(96087301947392., grad_fn=<ThAddBackward>))\n",
      "(398, tensor(63357693952., grad_fn=<ThAddBackward>))\n",
      "(400, tensor(5836768280576., grad_fn=<ThAddBackward>))\n",
      "(402, tensor(60317820625354752., grad_fn=<ThAddBackward>))\n",
      "(404, tensor(30862909374464., grad_fn=<ThAddBackward>))\n",
      "(406, tensor(332661155430400., grad_fn=<ThAddBackward>))\n",
      "(408, tensor(2675583753546207592448., grad_fn=<ThAddBackward>))\n",
      "(410, tensor(326176697805619012304896., grad_fn=<ThAddBackward>))\n",
      "(412, tensor(93980410773504., grad_fn=<ThAddBackward>))\n",
      "(414, tensor(71739673627189588732674048., grad_fn=<ThAddBackward>))\n",
      "(416, tensor(52461004454185828475731968., grad_fn=<ThAddBackward>))\n",
      "(418, tensor(26137366922107763925450752., grad_fn=<ThAddBackward>))\n",
      "(420, tensor(1750168974131200., grad_fn=<ThAddBackward>))\n",
      "(422, tensor(516530651529216., grad_fn=<ThAddBackward>))\n",
      "(424, tensor(61592828911812608., grad_fn=<ThAddBackward>))\n",
      "(426, tensor(5378764175310848., grad_fn=<ThAddBackward>))\n",
      "(428, tensor(10009333760., grad_fn=<ThAddBackward>))\n",
      "(430, tensor(555379982336., grad_fn=<ThAddBackward>))\n",
      "(432, tensor(503864983552., grad_fn=<ThAddBackward>))\n",
      "(434, tensor(23341478., grad_fn=<ThAddBackward>))\n",
      "(436, tensor(16279419904., grad_fn=<ThAddBackward>))\n",
      "(438, tensor(2231520985088., grad_fn=<ThAddBackward>))\n",
      "(440, tensor(62873900417024., grad_fn=<ThAddBackward>))\n",
      "(442, tensor(368207982493696., grad_fn=<ThAddBackward>))\n",
      "(444, tensor(19507088898280914944., grad_fn=<ThAddBackward>))\n",
      "(446, tensor(621507379200., grad_fn=<ThAddBackward>))\n",
      "(448, tensor(9357470066437855090049024., grad_fn=<ThAddBackward>))\n",
      "(450, tensor(39192126331813888., grad_fn=<ThAddBackward>))\n",
      "(452, tensor(148095303680., grad_fn=<ThAddBackward>))\n",
      "(454, tensor(2496086933504., grad_fn=<ThAddBackward>))\n",
      "(456, tensor(11357578468756143843835904., grad_fn=<ThAddBackward>))\n",
      "(458, tensor(31358778126363063746560., grad_fn=<ThAddBackward>))\n",
      "(460, tensor(338501807636480., grad_fn=<ThAddBackward>))\n",
      "(462, tensor(27742525204725760., grad_fn=<ThAddBackward>))\n",
      "(464, tensor(8382179256444447340906938368., grad_fn=<ThAddBackward>))\n",
      "(466, tensor(8448559791206714867558907904., grad_fn=<ThAddBackward>))\n",
      "(468, tensor(59970790257135190016., grad_fn=<ThAddBackward>))\n",
      "(470, tensor(934218334994432., grad_fn=<ThAddBackward>))\n",
      "(472, tensor(845398545530880., grad_fn=<ThAddBackward>))\n",
      "(474, tensor(36807053682933760., grad_fn=<ThAddBackward>))\n",
      "(476, tensor(26639149056., grad_fn=<ThAddBackward>))\n",
      "(478, tensor(34290094080., grad_fn=<ThAddBackward>))\n",
      "(480, tensor(60852652., grad_fn=<ThAddBackward>))\n",
      "(482, tensor(3272259615588352., grad_fn=<ThAddBackward>))\n",
      "(484, tensor(179257070321664., grad_fn=<ThAddBackward>))\n",
      "(486, tensor(66966240886784., grad_fn=<ThAddBackward>))\n",
      "(488, tensor(8589856208846848., grad_fn=<ThAddBackward>))\n",
      "(490, tensor(7423833791266816., grad_fn=<ThAddBackward>))\n",
      "(492, tensor(8308789254029312., grad_fn=<ThAddBackward>))\n",
      "(494, tensor(454099968040400173662208., grad_fn=<ThAddBackward>))\n",
      "(496, tensor(14535856488448., grad_fn=<ThAddBackward>))\n",
      "(498, tensor(6407862091776., grad_fn=<ThAddBackward>))\n",
      "(500, tensor(7239819591680., grad_fn=<ThAddBackward>))\n",
      "(502, tensor(76212726661120., grad_fn=<ThAddBackward>))\n",
      "(504, tensor(6916399750034518704128., grad_fn=<ThAddBackward>))\n",
      "(506, tensor(46032117301248., grad_fn=<ThAddBackward>))\n",
      "(508, tensor(45546281338142720., grad_fn=<ThAddBackward>))\n",
      "(510, tensor(20838209951384377665519616., grad_fn=<ThAddBackward>))\n",
      "(512, tensor(105918958985977640862772887552., grad_fn=<ThAddBackward>))\n",
      "(514, tensor(27913670778412523847680., grad_fn=<ThAddBackward>))\n",
      "(516, tensor(51351908253696., grad_fn=<ThAddBackward>))\n",
      "(518, tensor(102464195919872., grad_fn=<ThAddBackward>))\n",
      "(520, tensor(1154093496041125969920., grad_fn=<ThAddBackward>))\n",
      "(522, tensor(133299443859456., grad_fn=<ThAddBackward>))\n",
      "(524, tensor(37991280640., grad_fn=<ThAddBackward>))\n",
      "(526, tensor(140281380864., grad_fn=<ThAddBackward>))\n",
      "(528, tensor(55314936., grad_fn=<ThAddBackward>))\n",
      "(530, tensor(2866401280., grad_fn=<ThAddBackward>))\n",
      "(532, tensor(294388735410176., grad_fn=<ThAddBackward>))\n",
      "(534, tensor(120906868435451904., grad_fn=<ThAddBackward>))\n",
      "(536, tensor(1451679185625025609728., grad_fn=<ThAddBackward>))\n",
      "(538, tensor(736618184464438132736., grad_fn=<ThAddBackward>))\n",
      "(540, tensor(1608207036241953177993216., grad_fn=<ThAddBackward>))\n",
      "(542, tensor(3965211801913704419688448., grad_fn=<ThAddBackward>))\n",
      "(544, tensor(106454119874560., grad_fn=<ThAddBackward>))\n",
      "(546, tensor(31152597368832., grad_fn=<ThAddBackward>))\n",
      "(548, tensor(64825849806848., grad_fn=<ThAddBackward>))\n",
      "(550, tensor(170650721992049576715187388416., grad_fn=<ThAddBackward>))\n",
      "(552, tensor(50294212721450680320., grad_fn=<ThAddBackward>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, tensor(2359598660976640., grad_fn=<ThAddBackward>))\n",
      "(556, tensor(72449262069974302720., grad_fn=<ThAddBackward>))\n",
      "(558, tensor(359584740144700194816., grad_fn=<ThAddBackward>))\n",
      "(560, tensor(6108696263554617632733790208., grad_fn=<ThAddBackward>))\n",
      "(562, tensor(208772870728615221369241600., grad_fn=<ThAddBackward>))\n",
      "(564, tensor(3171457171456., grad_fn=<ThAddBackward>))\n",
      "(566, tensor(10764572164096., grad_fn=<ThAddBackward>))\n",
      "(568, tensor(153574555648., grad_fn=<ThAddBackward>))\n",
      "(570, tensor(6620892160., grad_fn=<ThAddBackward>))\n",
      "(572, tensor(94997472., grad_fn=<ThAddBackward>))\n",
      "(574, tensor(1872995712., grad_fn=<ThAddBackward>))\n",
      "(576, tensor(2007746560., grad_fn=<ThAddBackward>))\n",
      "(578, tensor(175907749888., grad_fn=<ThAddBackward>))\n",
      "(580, tensor(107712327188480., grad_fn=<ThAddBackward>))\n",
      "(582, tensor(1384666049282048., grad_fn=<ThAddBackward>))\n",
      "(584, tensor(1451678622675072188416., grad_fn=<ThAddBackward>))\n",
      "(586, tensor(350817995456512., grad_fn=<ThAddBackward>))\n",
      "(588, tensor(87076637914837073572921344., grad_fn=<ThAddBackward>))\n",
      "(590, tensor(6875776173087916032., grad_fn=<ThAddBackward>))\n",
      "(592, tensor(89248686080., grad_fn=<ThAddBackward>))\n",
      "(594, tensor(25909297938432., grad_fn=<ThAddBackward>))\n",
      "(596, tensor(159463768064., grad_fn=<ThAddBackward>))\n",
      "(598, tensor(394489.7812, grad_fn=<ThAddBackward>))\n",
      "(600, tensor(71225.9766, grad_fn=<ThAddBackward>))\n",
      "(602, tensor(359756.0312, grad_fn=<ThAddBackward>))\n",
      "(604, tensor(498290.6875, grad_fn=<ThAddBackward>))\n",
      "(606, tensor(48044.8984, grad_fn=<ThAddBackward>))\n",
      "(608, tensor(10897.5967, grad_fn=<ThAddBackward>))\n",
      "(610, tensor(13756.1797, grad_fn=<ThAddBackward>))\n",
      "(612, tensor(309689.4062, grad_fn=<ThAddBackward>))\n",
      "(614, tensor(163817.7656, grad_fn=<ThAddBackward>))\n",
      "(616, tensor(533051.2500, grad_fn=<ThAddBackward>))\n",
      "(618, tensor(98178377337113435038547968., grad_fn=<ThAddBackward>))\n",
      "(620, tensor(31062418628800771323968094208., grad_fn=<ThAddBackward>))\n",
      "(622, tensor(561172157468407496704., grad_fn=<ThAddBackward>))\n",
      "(624, tensor(5492958165419672720293448646656., grad_fn=<ThAddBackward>))\n",
      "(626, tensor(128818253222848336886759424., grad_fn=<ThAddBackward>))\n",
      "(628, tensor(104276640343580891433402368., grad_fn=<ThAddBackward>))\n",
      "(630, tensor(65322232096776781824., grad_fn=<ThAddBackward>))\n",
      "(632, tensor(126994542986174398464., grad_fn=<ThAddBackward>))\n",
      "(634, tensor(519030236327706624., grad_fn=<ThAddBackward>))\n",
      "(636, tensor(38659082235674624., grad_fn=<ThAddBackward>))\n",
      "(638, tensor(9740110302298060015796224., grad_fn=<ThAddBackward>))\n",
      "(640, tensor(83158817585814831104., grad_fn=<ThAddBackward>))\n",
      "(642, tensor(46425241026560., grad_fn=<ThAddBackward>))\n",
      "(644, tensor(91308265829495209984., grad_fn=<ThAddBackward>))\n",
      "(646, tensor(51466974412003442950144., grad_fn=<ThAddBackward>))\n",
      "(648, tensor(264364363874304., grad_fn=<ThAddBackward>))\n",
      "(650, tensor(18996032357661235216384., grad_fn=<ThAddBackward>))\n",
      "(652, tensor(10650051046056919040., grad_fn=<ThAddBackward>))\n",
      "(654, tensor(59000951406592., grad_fn=<ThAddBackward>))\n",
      "(656, tensor(32914696192., grad_fn=<ThAddBackward>))\n",
      "(658, tensor(931863216521216., grad_fn=<ThAddBackward>))\n",
      "(660, tensor(1385964410636790472376320., grad_fn=<ThAddBackward>))\n",
      "(662, tensor(1012428150262423237364285440., grad_fn=<ThAddBackward>))\n",
      "(664, tensor(28920512512000., grad_fn=<ThAddBackward>))\n",
      "(666, tensor(31866958643200., grad_fn=<ThAddBackward>))\n",
      "(668, tensor(14960619853709312., grad_fn=<ThAddBackward>))\n",
      "(670, tensor(1284602722485894155075584., grad_fn=<ThAddBackward>))\n",
      "(672, tensor(2973351018496., grad_fn=<ThAddBackward>))\n",
      "(674, tensor(429857538048., grad_fn=<ThAddBackward>))\n",
      "(676, tensor(5780425670656., grad_fn=<ThAddBackward>))\n",
      "(678, tensor(56446926454784., grad_fn=<ThAddBackward>))\n",
      "(680, tensor(64491758333127989133312., grad_fn=<ThAddBackward>))\n",
      "(682, tensor(2879189155840., grad_fn=<ThAddBackward>))\n",
      "(684, tensor(1028536023548547825664., grad_fn=<ThAddBackward>))\n",
      "(686, tensor(13233265311679518582243328., grad_fn=<ThAddBackward>))\n",
      "(688, tensor(582529974272., grad_fn=<ThAddBackward>))\n",
      "(690, tensor(9357470066437855090049024., grad_fn=<ThAddBackward>))\n",
      "(692, tensor(2172449558785117529309184., grad_fn=<ThAddBackward>))\n",
      "(694, tensor(7155062145024., grad_fn=<ThAddBackward>))\n",
      "(696, tensor(79974752256., grad_fn=<ThAddBackward>))\n",
      "(698, tensor(158782914560., grad_fn=<ThAddBackward>))\n",
      "(700, tensor(24963011349315584., grad_fn=<ThAddBackward>))\n",
      "(702, tensor(308260305371136., grad_fn=<ThAddBackward>))\n",
      "(704, tensor(35741224665088., grad_fn=<ThAddBackward>))\n",
      "(706, tensor(9912244224., grad_fn=<ThAddBackward>))\n",
      "(708, tensor(1759836355636439036953886720., grad_fn=<ThAddBackward>))\n",
      "(710, tensor(21535245847853268992., grad_fn=<ThAddBackward>))\n",
      "(712, tensor(37830887780795809792., grad_fn=<ThAddBackward>))\n",
      "(714, tensor(2317468786029012519547918352384., grad_fn=<ThAddBackward>))\n",
      "(716, tensor(13769811317077766885448317099048960., grad_fn=<ThAddBackward>))\n",
      "(718, tensor(6958399757209422528512., grad_fn=<ThAddBackward>))\n",
      "(720, tensor(16420556547031040., grad_fn=<ThAddBackward>))\n",
      "(722, tensor(1163031347200., grad_fn=<ThAddBackward>))\n",
      "(724, tensor(1113696894976., grad_fn=<ThAddBackward>))\n",
      "(726, tensor(2916834560., grad_fn=<ThAddBackward>))\n",
      "(728, tensor(1731174656., grad_fn=<ThAddBackward>))\n",
      "(730, tensor(94117339136., grad_fn=<ThAddBackward>))\n",
      "(732, tensor(168090681344., grad_fn=<ThAddBackward>))\n",
      "(734, tensor(12064504832., grad_fn=<ThAddBackward>))\n",
      "(736, tensor(256528728064., grad_fn=<ThAddBackward>))\n",
      "(738, tensor(92796694030188544., grad_fn=<ThAddBackward>))\n",
      "(740, tensor(175093451849728., grad_fn=<ThAddBackward>))\n",
      "(742, tensor(8418366754652160., grad_fn=<ThAddBackward>))\n",
      "(744, tensor(50888829313439382896640., grad_fn=<ThAddBackward>))\n",
      "(746, tensor(85916809401611315052544., grad_fn=<ThAddBackward>))\n",
      "(748, tensor(1846059404993859944448., grad_fn=<ThAddBackward>))\n",
      "(750, tensor(1447059521536., grad_fn=<ThAddBackward>))\n",
      "(752, tensor(3611885496696832., grad_fn=<ThAddBackward>))\n",
      "(754, tensor(1522798201353111863296., grad_fn=<ThAddBackward>))\n",
      "(756, tensor(44313870806823489037664256., grad_fn=<ThAddBackward>))\n",
      "(758, tensor(17645419999386402816., grad_fn=<ThAddBackward>))\n",
      "(760, tensor(447597302333308928., grad_fn=<ThAddBackward>))\n",
      "(762, tensor(5490205564109938764273418240., grad_fn=<ThAddBackward>))\n",
      "(764, tensor(37724977442384570484785152., grad_fn=<ThAddBackward>))\n",
      "(766, tensor(61215352826101760., grad_fn=<ThAddBackward>))\n",
      "(768, tensor(23966961893376., grad_fn=<ThAddBackward>))\n",
      "(770, tensor(458083495051264., grad_fn=<ThAddBackward>))\n",
      "(772, tensor(838796415760173367296., grad_fn=<ThAddBackward>))\n",
      "(774, tensor(1695070420992., grad_fn=<ThAddBackward>))\n",
      "(776, tensor(12657430102016., grad_fn=<ThAddBackward>))\n",
      "(778, tensor(439047296., grad_fn=<ThAddBackward>))\n",
      "(780, tensor(20166295420928., grad_fn=<ThAddBackward>))\n",
      "(782, tensor(1417665445888., grad_fn=<ThAddBackward>))\n",
      "(784, tensor(239872765853696., grad_fn=<ThAddBackward>))\n",
      "(786, tensor(105883577090048., grad_fn=<ThAddBackward>))\n",
      "(788, tensor(15515863117517329285513216., grad_fn=<ThAddBackward>))\n",
      "(790, tensor(19683053433520128., grad_fn=<ThAddBackward>))\n",
      "(792, tensor(218554616357322752., grad_fn=<ThAddBackward>))\n",
      "(794, tensor(128903418317295845376., grad_fn=<ThAddBackward>))\n",
      "(796, tensor(3133017423872., grad_fn=<ThAddBackward>))\n",
      "(798, tensor(293596790784., grad_fn=<ThAddBackward>))\n",
      "(800, tensor(24101215272960., grad_fn=<ThAddBackward>))\n",
      "(802, tensor(58880126091264., grad_fn=<ThAddBackward>))\n",
      "(804, tensor(2634760030298977599488., grad_fn=<ThAddBackward>))\n",
      "(806, tensor(915612368896., grad_fn=<ThAddBackward>))\n",
      "(808, tensor(11815744187460942299136., grad_fn=<ThAddBackward>))\n",
      "(810, tensor(29222889708087263887360., grad_fn=<ThAddBackward>))\n",
      "(812, tensor(419495414731868952667881472., grad_fn=<ThAddBackward>))\n",
      "(814, tensor(8800343857306284326912., grad_fn=<ThAddBackward>))\n",
      "(816, tensor(47912486195691520., grad_fn=<ThAddBackward>))\n",
      "(818, tensor(1773388372639744., grad_fn=<ThAddBackward>))\n",
      "(820, tensor(888559960064., grad_fn=<ThAddBackward>))\n",
      "(822, tensor(4137339322368., grad_fn=<ThAddBackward>))\n",
      "(824, tensor(435267584., grad_fn=<ThAddBackward>))\n",
      "(826, tensor(2495280896., grad_fn=<ThAddBackward>))\n",
      "(828, tensor(36985569280., grad_fn=<ThAddBackward>))\n",
      "(830, tensor(269004701696., grad_fn=<ThAddBackward>))\n",
      "(832, tensor(96425683697270784., grad_fn=<ThAddBackward>))\n",
      "(834, tensor(7660256625349124870373376., grad_fn=<ThAddBackward>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(836, tensor(8697132049896067563520., grad_fn=<ThAddBackward>))\n",
      "(838, tensor(548791056859136., grad_fn=<ThAddBackward>))\n",
      "(840, tensor(14867446345361973575680., grad_fn=<ThAddBackward>))\n",
      "(842, tensor(2252265280765952., grad_fn=<ThAddBackward>))\n",
      "(844, tensor(5623514112., grad_fn=<ThAddBackward>))\n",
      "(846, tensor(416905227665408., grad_fn=<ThAddBackward>))\n",
      "(848, tensor(125726450365346852372480., grad_fn=<ThAddBackward>))\n",
      "(850, tensor(9806093408366755840., grad_fn=<ThAddBackward>))\n",
      "(852, tensor(972710215680., grad_fn=<ThAddBackward>))\n",
      "(854, tensor(178037769371648., grad_fn=<ThAddBackward>))\n",
      "(856, tensor(24273295763343303170326528., grad_fn=<ThAddBackward>))\n",
      "(858, tensor(2491274501746023464960., grad_fn=<ThAddBackward>))\n",
      "(860, tensor(1484825115932519038976., grad_fn=<ThAddBackward>))\n",
      "(862, tensor(11936741720064., grad_fn=<ThAddBackward>))\n",
      "(864, tensor(1310520149803008., grad_fn=<ThAddBackward>))\n",
      "(866, tensor(956228409362556649472., grad_fn=<ThAddBackward>))\n",
      "(868, tensor(1964964577280., grad_fn=<ThAddBackward>))\n",
      "(870, tensor(361794624., grad_fn=<ThAddBackward>))\n",
      "(872, tensor(48712302592., grad_fn=<ThAddBackward>))\n",
      "(874, tensor(1239245696., grad_fn=<ThAddBackward>))\n",
      "(876, tensor(2107184640., grad_fn=<ThAddBackward>))\n",
      "(878, tensor(8796695953408., grad_fn=<ThAddBackward>))\n",
      "(880, tensor(40562463866880., grad_fn=<ThAddBackward>))\n",
      "(882, tensor(21806305546738188943360., grad_fn=<ThAddBackward>))\n",
      "(884, tensor(6283522405199025012736., grad_fn=<ThAddBackward>))\n",
      "(886, tensor(3047742616109056., grad_fn=<ThAddBackward>))\n",
      "(888, tensor(3985080386432970365337600., grad_fn=<ThAddBackward>))\n",
      "(890, tensor(22522019971072., grad_fn=<ThAddBackward>))\n",
      "(892, tensor(719160704., grad_fn=<ThAddBackward>))\n",
      "(894, tensor(17182410752., grad_fn=<ThAddBackward>))\n",
      "(896, tensor(11573474549708822008561664., grad_fn=<ThAddBackward>))\n",
      "(898, tensor(907947.8750, grad_fn=<ThAddBackward>))\n",
      "(900, tensor(399018.9375, grad_fn=<ThAddBackward>))\n",
      "(902, tensor(173960.1406, grad_fn=<ThAddBackward>))\n",
      "(904, tensor(68612.4062, grad_fn=<ThAddBackward>))\n",
      "(906, tensor(10872.3555, grad_fn=<ThAddBackward>))\n",
      "(908, tensor(10186.2939, grad_fn=<ThAddBackward>))\n",
      "(910, tensor(101109.9531, grad_fn=<ThAddBackward>))\n",
      "(912, tensor(140980.4688, grad_fn=<ThAddBackward>))\n",
      "(914, tensor(57213.7773, grad_fn=<ThAddBackward>))\n",
      "(916, tensor(55906105010708130299904., grad_fn=<ThAddBackward>))\n",
      "(918, tensor(3437556500225299841024., grad_fn=<ThAddBackward>))\n",
      "(920, tensor(140119580412703932416., grad_fn=<ThAddBackward>))\n",
      "(922, tensor(266128780836405940060160., grad_fn=<ThAddBackward>))\n",
      "(924, tensor(336212903138112459671339008., grad_fn=<ThAddBackward>))\n",
      "(926, tensor(13609595879253413684890597542854656., grad_fn=<ThAddBackward>))\n",
      "(928, tensor(47880779357776152212013056., grad_fn=<ThAddBackward>))\n",
      "(930, tensor(58546790860849152., grad_fn=<ThAddBackward>))\n",
      "(932, tensor(1972368436101120., grad_fn=<ThAddBackward>))\n",
      "(934, tensor(198992948363264., grad_fn=<ThAddBackward>))\n",
      "(936, tensor(71847543336557608960., grad_fn=<ThAddBackward>))\n",
      "(938, tensor(60075024384., grad_fn=<ThAddBackward>))\n",
      "(940, tensor(17089952743424., grad_fn=<ThAddBackward>))\n",
      "(942, tensor(346126548992000., grad_fn=<ThAddBackward>))\n",
      "(944, tensor(2844351364507312848896., grad_fn=<ThAddBackward>))\n",
      "(946, tensor(364992662601728., grad_fn=<ThAddBackward>))\n",
      "(948, tensor(3264411671901367173120., grad_fn=<ThAddBackward>))\n",
      "(950, tensor(433065022789255168., grad_fn=<ThAddBackward>))\n",
      "(952, tensor(127898951680., grad_fn=<ThAddBackward>))\n",
      "(954, tensor(228191109120., grad_fn=<ThAddBackward>))\n",
      "(956, tensor(1055698321408., grad_fn=<ThAddBackward>))\n",
      "(958, tensor(17861964046994467979264., grad_fn=<ThAddBackward>))\n",
      "(960, tensor(409735383744512., grad_fn=<ThAddBackward>))\n",
      "(962, tensor(7620419649536., grad_fn=<ThAddBackward>))\n",
      "(964, tensor(2746353036615730855936., grad_fn=<ThAddBackward>))\n",
      "(966, tensor(249250390736896., grad_fn=<ThAddBackward>))\n",
      "(968, tensor(53046140792192630784., grad_fn=<ThAddBackward>))\n",
      "(970, tensor(56850179994681344., grad_fn=<ThAddBackward>))\n",
      "(972, tensor(76429533184., grad_fn=<ThAddBackward>))\n",
      "(974, tensor(767804637184., grad_fn=<ThAddBackward>))\n",
      "(976, tensor(26568875311104., grad_fn=<ThAddBackward>))\n",
      "(978, tensor(175315084644450304., grad_fn=<ThAddBackward>))\n",
      "(980, tensor(8043145260483739648., grad_fn=<ThAddBackward>))\n",
      "(982, tensor(4534856297634307506176., grad_fn=<ThAddBackward>))\n",
      "(984, tensor(314907070862196736., grad_fn=<ThAddBackward>))\n",
      "(986, tensor(14661461831505208672256., grad_fn=<ThAddBackward>))\n",
      "(988, tensor(13074658911846400., grad_fn=<ThAddBackward>))\n",
      "(990, tensor(174635019901033663954944., grad_fn=<ThAddBackward>))\n",
      "(992, tensor(34416978034688., grad_fn=<ThAddBackward>))\n",
      "(994, tensor(27350362226688., grad_fn=<ThAddBackward>))\n",
      "(996, tensor(28123875328., grad_fn=<ThAddBackward>))\n",
      "(998, tensor(2080118538240., grad_fn=<ThAddBackward>))\n",
      "(1000, tensor(35154925793050624., grad_fn=<ThAddBackward>))\n",
      "(1002, tensor(24996860657664., grad_fn=<ThAddBackward>))\n",
      "(1004, tensor(131585265369088., grad_fn=<ThAddBackward>))\n",
      "(1006, tensor(2674768320538676822016., grad_fn=<ThAddBackward>))\n",
      "(1008, tensor(326176661776821993340928., grad_fn=<ThAddBackward>))\n",
      "(1010, tensor(39661024051200., grad_fn=<ThAddBackward>))\n",
      "(1012, tensor(71739673627189588732674048., grad_fn=<ThAddBackward>))\n",
      "(1014, tensor(52461004454185828475731968., grad_fn=<ThAddBackward>))\n",
      "(1016, tensor(26137366922107763925450752., grad_fn=<ThAddBackward>))\n",
      "(1018, tensor(1435554835070976., grad_fn=<ThAddBackward>))\n",
      "(1020, tensor(177782252371968., grad_fn=<ThAddBackward>))\n",
      "(1022, tensor(5985717142421504., grad_fn=<ThAddBackward>))\n",
      "(1024, tensor(2245394675269632., grad_fn=<ThAddBackward>))\n",
      "(1026, tensor(2450600192., grad_fn=<ThAddBackward>))\n",
      "(1028, tensor(440112939008., grad_fn=<ThAddBackward>))\n",
      "(1030, tensor(160244875264., grad_fn=<ThAddBackward>))\n",
      "(1032, tensor(11222355., grad_fn=<ThAddBackward>))\n",
      "(1034, tensor(1728115456., grad_fn=<ThAddBackward>))\n",
      "(1036, tensor(1125877153792., grad_fn=<ThAddBackward>))\n",
      "(1038, tensor(55668836925440., grad_fn=<ThAddBackward>))\n",
      "(1040, tensor(329252796891136., grad_fn=<ThAddBackward>))\n",
      "(1042, tensor(19507075704141381632., grad_fn=<ThAddBackward>))\n",
      "(1044, tensor(558905425920., grad_fn=<ThAddBackward>))\n",
      "(1046, tensor(9357470066437855090049024., grad_fn=<ThAddBackward>))\n",
      "(1048, tensor(36418363437613056., grad_fn=<ThAddBackward>))\n",
      "(1050, tensor(105396912128., grad_fn=<ThAddBackward>))\n",
      "(1052, tensor(2358571958272., grad_fn=<ThAddBackward>))\n",
      "(1054, tensor(11357573857070125416448000., grad_fn=<ThAddBackward>))\n",
      "(1056, tensor(31358701565169398448128., grad_fn=<ThAddBackward>))\n",
      "(1058, tensor(207895392157696., grad_fn=<ThAddBackward>))\n",
      "(1060, tensor(23506781212770304., grad_fn=<ThAddBackward>))\n",
      "(1062, tensor(8382179256444447340906938368., grad_fn=<ThAddBackward>))\n",
      "(1064, tensor(8448559791206714867558907904., grad_fn=<ThAddBackward>))\n",
      "(1066, tensor(51985745390086389760., grad_fn=<ThAddBackward>))\n",
      "(1068, tensor(763615388893184., grad_fn=<ThAddBackward>))\n",
      "(1070, tensor(347706157432832., grad_fn=<ThAddBackward>))\n",
      "(1072, tensor(14043845125734400., grad_fn=<ThAddBackward>))\n",
      "(1074, tensor(900783040., grad_fn=<ThAddBackward>))\n",
      "(1076, tensor(4489965568., grad_fn=<ThAddBackward>))\n",
      "(1078, tensor(20054328., grad_fn=<ThAddBackward>))\n",
      "(1080, tensor(4607578734592., grad_fn=<ThAddBackward>))\n",
      "(1082, tensor(67759903866880., grad_fn=<ThAddBackward>))\n",
      "(1084, tensor(32694132015104., grad_fn=<ThAddBackward>))\n",
      "(1086, tensor(7715940422647808., grad_fn=<ThAddBackward>))\n",
      "(1088, tensor(8023985677664256., grad_fn=<ThAddBackward>))\n",
      "(1090, tensor(7900890841219072., grad_fn=<ThAddBackward>))\n",
      "(1092, tensor(454099968040400173662208., grad_fn=<ThAddBackward>))\n",
      "(1094, tensor(14695825145856., grad_fn=<ThAddBackward>))\n",
      "(1096, tensor(9992527675392., grad_fn=<ThAddBackward>))\n",
      "(1098, tensor(3365871026176., grad_fn=<ThAddBackward>))\n",
      "(1100, tensor(25207320346624., grad_fn=<ThAddBackward>))\n",
      "(1102, tensor(6915828355831796072448., grad_fn=<ThAddBackward>))\n",
      "(1104, tensor(26543273279488., grad_fn=<ThAddBackward>))\n",
      "(1106, tensor(11180408683102208., grad_fn=<ThAddBackward>))\n",
      "(1108, tensor(20838209951384377665519616., grad_fn=<ThAddBackward>))\n",
      "(1110, tensor(105918958985977640862772887552., grad_fn=<ThAddBackward>))\n",
      "(1112, tensor(27913402814234695303168., grad_fn=<ThAddBackward>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1114, tensor(26135414964224., grad_fn=<ThAddBackward>))\n",
      "(1116, tensor(61347370893312., grad_fn=<ThAddBackward>))\n",
      "(1118, tensor(1148939900323786391552., grad_fn=<ThAddBackward>))\n",
      "(1120, tensor(78125899710464., grad_fn=<ThAddBackward>))\n",
      "(1122, tensor(8309085184., grad_fn=<ThAddBackward>))\n",
      "(1124, tensor(77080420352., grad_fn=<ThAddBackward>))\n",
      "(1126, tensor(29595048., grad_fn=<ThAddBackward>))\n",
      "(1128, tensor(1136444288., grad_fn=<ThAddBackward>))\n",
      "(1130, tensor(66212566401024., grad_fn=<ThAddBackward>))\n",
      "(1132, tensor(74016210794053632., grad_fn=<ThAddBackward>))\n",
      "(1134, tensor(1451677496775165345792., grad_fn=<ThAddBackward>))\n",
      "(1136, tensor(735911119322940964864., grad_fn=<ThAddBackward>))\n",
      "(1138, tensor(1608207036241953177993216., grad_fn=<ThAddBackward>))\n",
      "(1140, tensor(4200267420660315319173120., grad_fn=<ThAddBackward>))\n",
      "(1142, tensor(23149225705472., grad_fn=<ThAddBackward>))\n",
      "(1144, tensor(19023590850560., grad_fn=<ThAddBackward>))\n",
      "(1146, tensor(31795951173632., grad_fn=<ThAddBackward>))\n",
      "(1148, tensor(170650721992049576715187388416., grad_fn=<ThAddBackward>))\n",
      "(1150, tensor(37537401739063328768., grad_fn=<ThAddBackward>))\n",
      "(1152, tensor(559106729443328., grad_fn=<ThAddBackward>))\n",
      "(1154, tensor(70618469656610996224., grad_fn=<ThAddBackward>))\n",
      "(1156, tensor(359584740144700194816., grad_fn=<ThAddBackward>))\n",
      "(1158, tensor(6095807154535435294828658688., grad_fn=<ThAddBackward>))\n",
      "(1160, tensor(208772870728615221369241600., grad_fn=<ThAddBackward>))\n",
      "(1162, tensor(1578728030208., grad_fn=<ThAddBackward>))\n",
      "(1164, tensor(4354579365888., grad_fn=<ThAddBackward>))\n",
      "(1166, tensor(48782360576., grad_fn=<ThAddBackward>))\n",
      "(1168, tensor(5077914112., grad_fn=<ThAddBackward>))\n",
      "(1170, tensor(19051160., grad_fn=<ThAddBackward>))\n",
      "(1172, tensor(603460800., grad_fn=<ThAddBackward>))\n",
      "(1174, tensor(781974400., grad_fn=<ThAddBackward>))\n",
      "(1176, tensor(80753754112., grad_fn=<ThAddBackward>))\n",
      "(1178, tensor(54018164391936., grad_fn=<ThAddBackward>))\n",
      "(1180, tensor(610767166504960., grad_fn=<ThAddBackward>))\n",
      "(1182, tensor(1451677074562700279808., grad_fn=<ThAddBackward>))\n",
      "(1184, tensor(243785531392000., grad_fn=<ThAddBackward>))\n",
      "(1186, tensor(87076637914837073572921344., grad_fn=<ThAddBackward>))\n",
      "(1188, tensor(3318845611872092160., grad_fn=<ThAddBackward>))\n",
      "(1190, tensor(62029250560., grad_fn=<ThAddBackward>))\n",
      "(1192, tensor(9964980535296., grad_fn=<ThAddBackward>))\n",
      "(1194, tensor(52539408384., grad_fn=<ThAddBackward>))\n",
      "(1196, tensor(328016.1875, grad_fn=<ThAddBackward>))\n",
      "(1198, tensor(59038.3047, grad_fn=<ThAddBackward>))\n",
      "(1200, tensor(275243.3750, grad_fn=<ThAddBackward>))\n",
      "(1202, tensor(444894., grad_fn=<ThAddBackward>))\n",
      "(1204, tensor(22683.5625, grad_fn=<ThAddBackward>))\n",
      "(1206, tensor(7534.6548, grad_fn=<ThAddBackward>))\n",
      "(1208, tensor(9209.6455, grad_fn=<ThAddBackward>))\n",
      "(1210, tensor(269821.6875, grad_fn=<ThAddBackward>))\n",
      "(1212, tensor(118344.9766, grad_fn=<ThAddBackward>))\n",
      "(1214, tensor(459581.0312, grad_fn=<ThAddBackward>))\n",
      "(1216, tensor(98178377337113435038547968., grad_fn=<ThAddBackward>))\n",
      "(1218, tensor(31062418628800771323968094208., grad_fn=<ThAddBackward>))\n",
      "(1220, tensor(558923770538814865408., grad_fn=<ThAddBackward>))\n",
      "(1222, tensor(5492958165419672720293448646656., grad_fn=<ThAddBackward>))\n",
      "(1224, tensor(128818253222848336886759424., grad_fn=<ThAddBackward>))\n",
      "(1226, tensor(104276640343580891433402368., grad_fn=<ThAddBackward>))\n",
      "(1228, tensor(54500772685507723264., grad_fn=<ThAddBackward>))\n",
      "(1230, tensor(122399112147652050944., grad_fn=<ThAddBackward>))\n",
      "(1232, tensor(310105228705792000., grad_fn=<ThAddBackward>))\n",
      "(1234, tensor(32351044440686592., grad_fn=<ThAddBackward>))\n",
      "(1236, tensor(9740109149376555408949248., grad_fn=<ThAddBackward>))\n",
      "(1238, tensor(78603822386915573760., grad_fn=<ThAddBackward>))\n",
      "(1240, tensor(25338134396928., grad_fn=<ThAddBackward>))\n",
      "(1242, tensor(87671380431974957056., grad_fn=<ThAddBackward>))\n",
      "(1244, tensor(51466929376007169245184., grad_fn=<ThAddBackward>))\n",
      "(1246, tensor(196288595361792., grad_fn=<ThAddBackward>))\n",
      "(1248, tensor(18993348212283322400768., grad_fn=<ThAddBackward>))\n",
      "(1250, tensor(4560548832131153920., grad_fn=<ThAddBackward>))\n",
      "(1252, tensor(43454088347648., grad_fn=<ThAddBackward>))\n",
      "(1254, tensor(13065955328., grad_fn=<ThAddBackward>))\n",
      "(1256, tensor(465689009717248., grad_fn=<ThAddBackward>))\n",
      "(1258, tensor(1383497590962496047415296., grad_fn=<ThAddBackward>))\n",
      "(1260, tensor(1012428150262423237364285440., grad_fn=<ThAddBackward>))\n",
      "(1262, tensor(14426197458944., grad_fn=<ThAddBackward>))\n",
      "(1264, tensor(17246617337856., grad_fn=<ThAddBackward>))\n",
      "(1266, tensor(9882180729700352., grad_fn=<ThAddBackward>))\n",
      "(1268, tensor(1260462852022435993092096., grad_fn=<ThAddBackward>))\n",
      "(1270, tensor(1751302012928., grad_fn=<ThAddBackward>))\n",
      "(1272, tensor(228273684480., grad_fn=<ThAddBackward>))\n",
      "(1274, tensor(6293859860480., grad_fn=<ThAddBackward>))\n",
      "(1276, tensor(32633035685888., grad_fn=<ThAddBackward>))\n",
      "(1278, tensor(64491749325928734392320., grad_fn=<ThAddBackward>))\n",
      "(1280, tensor(1387904892928., grad_fn=<ThAddBackward>))\n",
      "(1282, tensor(1028460306779812659200., grad_fn=<ThAddBackward>))\n",
      "(1284, tensor(13233265311679518582243328., grad_fn=<ThAddBackward>))\n",
      "(1286, tensor(543431720960., grad_fn=<ThAddBackward>))\n",
      "(1288, tensor(9357470066437855090049024., grad_fn=<ThAddBackward>))\n",
      "(1290, tensor(2172449558785117529309184., grad_fn=<ThAddBackward>))\n",
      "(1292, tensor(4760790368256., grad_fn=<ThAddBackward>))\n",
      "(1294, tensor(55788724224., grad_fn=<ThAddBackward>))\n",
      "(1296, tensor(114267725824., grad_fn=<ThAddBackward>))\n",
      "(1298, tensor(12089919547637760., grad_fn=<ThAddBackward>))\n",
      "(1300, tensor(234109792157696., grad_fn=<ThAddBackward>))\n",
      "(1302, tensor(14794062036992., grad_fn=<ThAddBackward>))\n",
      "(1304, tensor(4030094080., grad_fn=<ThAddBackward>))\n",
      "(1306, tensor(1759836355636439036953886720., grad_fn=<ThAddBackward>))\n",
      "(1308, tensor(9519993885749673984., grad_fn=<ThAddBackward>))\n",
      "(1310, tensor(28159277838645592064., grad_fn=<ThAddBackward>))\n",
      "(1312, tensor(2317468786029012519547918352384., grad_fn=<ThAddBackward>))\n",
      "(1314, tensor(13769811317077766885448317099048960., grad_fn=<ThAddBackward>))\n",
      "(1316, tensor(6958387935260400680960., grad_fn=<ThAddBackward>))\n",
      "(1318, tensor(10593392954179584., grad_fn=<ThAddBackward>))\n",
      "(1320, tensor(392495693824., grad_fn=<ThAddBackward>))\n",
      "(1322, tensor(864133185536., grad_fn=<ThAddBackward>))\n",
      "(1324, tensor(867583488., grad_fn=<ThAddBackward>))\n",
      "(1326, tensor(861618432., grad_fn=<ThAddBackward>))\n",
      "(1328, tensor(21006649344., grad_fn=<ThAddBackward>))\n",
      "(1330, tensor(49833680896., grad_fn=<ThAddBackward>))\n",
      "(1332, tensor(6604865536., grad_fn=<ThAddBackward>))\n",
      "(1334, tensor(64004608000., grad_fn=<ThAddBackward>))\n",
      "(1336, tensor(41434043425751040., grad_fn=<ThAddBackward>))\n",
      "(1338, tensor(138474812342272., grad_fn=<ThAddBackward>))\n",
      "(1340, tensor(7253775634923520., grad_fn=<ThAddBackward>))\n",
      "(1342, tensor(50888829313439382896640., grad_fn=<ThAddBackward>))\n",
      "(1344, tensor(85916809401611315052544., grad_fn=<ThAddBackward>))\n",
      "(1346, tensor(1845147285331829063680., grad_fn=<ThAddBackward>))\n",
      "(1348, tensor(916150288384., grad_fn=<ThAddBackward>))\n",
      "(1350, tensor(1146211075620864., grad_fn=<ThAddBackward>))\n",
      "(1352, tensor(1521963909522141478912., grad_fn=<ThAddBackward>))\n",
      "(1354, tensor(44313870806823489037664256., grad_fn=<ThAddBackward>))\n",
      "(1356, tensor(14126267008433520640., grad_fn=<ThAddBackward>))\n",
      "(1358, tensor(226925198379581440., grad_fn=<ThAddBackward>))\n",
      "(1360, tensor(5490205564109938764273418240., grad_fn=<ThAddBackward>))\n",
      "(1362, tensor(37724977442384570484785152., grad_fn=<ThAddBackward>))\n",
      "(1364, tensor(45983002202734592., grad_fn=<ThAddBackward>))\n",
      "(1366, tensor(13919005442048., grad_fn=<ThAddBackward>))\n",
      "(1368, tensor(352134436487168., grad_fn=<ThAddBackward>))\n",
      "(1370, tensor(835108812090287063040., grad_fn=<ThAddBackward>))\n",
      "(1372, tensor(200508194816., grad_fn=<ThAddBackward>))\n",
      "(1374, tensor(8662728310784., grad_fn=<ThAddBackward>))\n",
      "(1376, tensor(162292736., grad_fn=<ThAddBackward>))\n",
      "(1378, tensor(10146015084544., grad_fn=<ThAddBackward>))\n",
      "(1380, tensor(627382419456., grad_fn=<ThAddBackward>))\n",
      "(1382, tensor(177881271500800., grad_fn=<ThAddBackward>))\n",
      "(1384, tensor(81814722969600., grad_fn=<ThAddBackward>))\n",
      "(1386, tensor(15515863117517329285513216., grad_fn=<ThAddBackward>))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1388, tensor(20372726397009920., grad_fn=<ThAddBackward>))\n",
      "(1390, tensor(208484069099438080., grad_fn=<ThAddBackward>))\n",
      "(1392, tensor(125896588266863329280., grad_fn=<ThAddBackward>))\n",
      "(1394, tensor(1505405042688., grad_fn=<ThAddBackward>))\n",
      "(1396, tensor(385449295872., grad_fn=<ThAddBackward>))\n",
      "(1398, tensor(8738405613568., grad_fn=<ThAddBackward>))\n",
      "(1400, tensor(36100206755840., grad_fn=<ThAddBackward>))\n",
      "(1402, tensor(2631343768506640367616., grad_fn=<ThAddBackward>))\n",
      "(1404, tensor(441017663488., grad_fn=<ThAddBackward>))\n",
      "(1406, tensor(11811632401001153036288., grad_fn=<ThAddBackward>))\n",
      "(1408, tensor(29222889708087263887360., grad_fn=<ThAddBackward>))\n",
      "(1410, tensor(419495414731868952667881472., grad_fn=<ThAddBackward>))\n",
      "(1412, tensor(8800341605506470641664., grad_fn=<ThAddBackward>))\n",
      "(1414, tensor(25867028950679552., grad_fn=<ThAddBackward>))\n",
      "(1416, tensor(656006929448960., grad_fn=<ThAddBackward>))\n",
      "(1418, tensor(253433331712., grad_fn=<ThAddBackward>))\n",
      "(1420, tensor(1449525116928., grad_fn=<ThAddBackward>))\n",
      "(1422, tensor(544556160., grad_fn=<ThAddBackward>))\n",
      "(1424, tensor(860942080., grad_fn=<ThAddBackward>))\n",
      "(1426, tensor(18891333632., grad_fn=<ThAddBackward>))\n",
      "(1428, tensor(171680464896., grad_fn=<ThAddBackward>))\n",
      "(1430, tensor(56568653478363136., grad_fn=<ThAddBackward>))\n",
      "(1432, tensor(7660256625349124870373376., grad_fn=<ThAddBackward>))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-5c94a5828d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#print(\"up\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Housekeeping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/torch/optim/adam.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for it in range(100000):\n",
    "    #print(\"begin\")\n",
    "    X = obs[it%(len(obs)-1)]\n",
    "    X = Variable(torch.from_numpy(X).float().view(-1))\n",
    "\n",
    "    # Forward\n",
    "    #print(\"forward\")\n",
    "    z_mu, z_var = Q(X)\n",
    "    #print(z_mu.shape, z_var.shape)\n",
    "    z = sample_z(z_mu, z_var)\n",
    "    #print(z.shape)\n",
    "    X_sample = P(z)\n",
    "\n",
    "\n",
    "    # Loss\n",
    "    #print(\"loss\")\n",
    "    recon_loss = nn.binary_cross_entropy(X_sample, X, size_average=False)\n",
    "    kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1. - z_var)\n",
    "    loss = recon_loss + kl_loss\n",
    "    if it % 2 == 0:\n",
    "        print(it, loss)\n",
    "\n",
    "    # Backward\n",
    "    #print(\"back\")\n",
    "    loss.backward()\n",
    "\n",
    "    # Update\n",
    "    #print(\"up\")\n",
    "    solver.step()\n",
    "\n",
    "    # Housekeeping\n",
    "    #print(\"house\")\n",
    "    for p in params:\n",
    "        p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
